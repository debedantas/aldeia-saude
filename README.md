# AldeIA SaÃºde

Web app que usa RAG (Retrieval-Augmented Generation) para transformar relatos de saÃºde (Ã¡udio ou texto) com vocabulÃ¡rio indÃ­gena Yanomami em dados estruturados, gerando explicaÃ§Ãµes mÃ©dicas contextualizadas.

## VisÃ£o Geral do MVP

### Fluxo Principal

1. **IngestÃ£o de Dados** (`POST /api/relatos/texto` ou `/audio`)

   - Recebe relato em texto livre ou Ã¡udio
   - Ãudio Ã© transcrito usando Google Gemini com prompt enriquecido para vocabulÃ¡rio Yanomami
   - Relato original Ã© salvo imediatamente no banco (SQLite com SQLAlchemy)
   - Sistema retorna rapidamente o `case_id`

2. **EstruturaÃ§Ã£o de Dados** (PrÃ³xima fase - em background)

   - LLM processa o relato e extrai dados estruturados:
     - **Dados do Paciente**: nome, idade (texto descritivo), sexo (M/F/Indefinido)
     - **Sintomas**: descriÃ§Ã£o em portuguÃªs, termos indÃ­genas, categoria
     - **Dados ClÃ­nicos**: duraÃ§Ã£o dos sintomas, fator desencadeante, temperatura (Â°C), pressÃ£o arterial
   - RAG busca termos Yanomami relacionados na base de conhecimento (FAISS)
   - Dados estruturados sÃ£o salvos vinculados ao caso

3. **GeraÃ§Ã£o de ExplicaÃ§Ãµes MÃ©dicas** (Fase futura)

   - Com base nos dados estruturados, LLM gera explicaÃ§Ã£o contextualizada
   - Inclui nÃ­vel de gravidade e recomendaÃ§Ãµes bÃ¡sicas

4. **VisualizaÃ§Ã£o** (Frontend React - Fase 5)
   - Dashboard com casos recentes e estatÃ­sticas
   - Detalhes do caso: relato original + dados estruturados + explicaÃ§Ã£o

### Arquitetura TÃ©cnica Atual

- **Backend**: FastAPI com SQLAlchemy ORM
- **Banco de Dados**: SQLite com 3 tabelas principais:
  - `cases`: Relatos originais (Ã¡udio/texto)
  - `structured_data`: Dados extraÃ­dos via LLM + RAG
  - `medical_explanations`: ExplicaÃ§Ãµes geradas
- **Repository Pattern**: Camada de acesso a dados desacoplada
- **LLM**: Google Gemini (transcriÃ§Ã£o e estruturaÃ§Ã£o)
- **RAG**: LangChain + FAISS + HuggingFace embeddings
- **Documento Base**: `Saude_Yanomami.pdf` indexado com vocabulÃ¡rio indÃ­gena

### Status Atual

âœ… **Fase 1**: RAG implementado (indexaÃ§Ã£o do PDF Yanomami)  
âœ… **Fase 2**: IngestÃ£o de texto e Ã¡udio com transcriÃ§Ã£o  
âœ… **Infraestrutura**: SQLAlchemy + Repository Pattern  
ğŸ”´ **Fase 3**: EstruturaÃ§Ã£o de dados (prÃ³xima)  
ğŸ”´ **Fase 4**: ExplicaÃ§Ãµes mÃ©dicas  
ğŸ”´ **Fase 5**: Interface web

## Principais objetivos

- Processar relatos livres de saÃºde e extrair informaÃ§Ãµes estruturadas utilizando InteligÃªncia Artificial.
- Integrar vocabulÃ¡rio indÃ­gena Yanomami atravÃ©s de RAG para mapear termos nativos aos sintomas relatados.
- Gerar explicaÃ§Ãµes mÃ©dicas baseadas nos dados estruturados.
- Visualizar casos registrados em dashboard bÃ¡sico para monitoramento.

## ContribuiÃ§Ãµes

- Reduz a dependÃªncia de registros mÃ©dicos manuais e formulÃ¡rios, atacando erros, incompletudes e perda de informaÃ§Ã£o em contextos remotos onde o AIS (Agente IndÃ­gena de SaÃºde) estÃ¡ sobrecarregado.
- Aproveita relatos livres (orais ou textuais) e aplica IA para transcrever e estruturar automaticamente os dados de saÃºde.
- Preserva e valoriza o vocabulÃ¡rio indÃ­gena Yanomami, mapeando termos nativos relacionados Ã  saÃºde.
- Acelera o processo de registro e organizaÃ§Ã£o dos casos, eliminando retrabalho e reduzindo nÃ£o conformidades comuns em registros convencionais.
- Fornece explicaÃ§Ãµes mÃ©dicas contextualizadas baseadas nos sintomas identificados.
- Transforma relatos dispersos em informaÃ§Ã£o Ãºtil e centrada na comunidade, produzindo anÃ¡lises que refletem a realidade da populaÃ§Ã£o indÃ­gena.
- Facilita o acompanhamento de casos atravÃ©s de dashboard visual, para fortalecer a visÃ£o do AIS.

## Arquitetura do Sistema

### Tecnologias Utilizadas

- **Backend**: Python com FastAPI
- **LLM**: Google Gemini (transcriÃ§Ã£o de Ã¡udio e estruturaÃ§Ã£o dos dados)
- **RAG**: LangChain + FAISS (indexaÃ§Ã£o do vocabulÃ¡rio Yanomami)
- **Embeddings**: HuggingFace (sentence-transformers)
- **PDF Parser**: PyPDF
- **Frontend**: React (interface web)
- **Banco**: SQLite

### Estrutura do Projeto

```
aldeia-saude/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                          # AplicaÃ§Ã£o FastAPI principal
â”‚   â”œâ”€â”€ requirements.txt                 # DependÃªncias Python
â”‚   â”‚
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ ingest.py               # Endpoints de entrada (texto/Ã¡udio)
â”‚   â”‚   â”‚   â”œâ”€â”€ cases.py                # Endpoints de consulta de casos
â”‚   â”‚   â”‚   â”œâ”€â”€ structure.py            # (Fase 3) EstruturaÃ§Ã£o de dados
â”‚   â”‚   â”‚   â””â”€â”€ explanation.py          # (Fase 4) GeraÃ§Ã£o de explicaÃ§Ãµes
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”œâ”€â”€ case.py                 # Schemas Pydantic de casos
â”‚   â”‚   â”‚   â”œâ”€â”€ structured_case.py      # (Fase 3) Schema de dados estruturados
â”‚   â”‚   â”‚   â””â”€â”€ explanation.py          # (Fase 4) Schema de explicaÃ§Ãµes
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ asr_service.py          # TranscriÃ§Ã£o de Ã¡udio (Gemini)
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py          # (Fase 3) ServiÃ§o RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ structure_service.py    # (Fase 3) EstruturaÃ§Ã£o com LLM
â”‚   â”‚   â”‚   â””â”€â”€ explanation_service.py  # (Fase 4) GeraÃ§Ã£o de explicaÃ§Ãµes
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”‚   â”œâ”€â”€ connection.py           # ConexÃ£o e operaÃ§Ãµes SQLite
â”‚   â”‚   â”‚   â””â”€â”€ aldeia_saude.db         # Banco de dados (gerado)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ text_cleaning.py        # Limpeza de texto
â”‚   â”‚       â””â”€â”€ validation.py           # ValidaÃ§Ãµes
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py             # Pipeline RAG completo
â”‚   â”‚   â””â”€â”€ faiss_index/                # Ãndice vetorial (gerado)
â”‚   â”‚
â”‚   â”œâ”€â”€ asr/
â”‚   â”‚   â”œâ”€â”€ transcriber.py              # Classe de transcriÃ§Ã£o (legado)
â”‚   â”‚   â””â”€â”€ audio_samples/              # Ãudios enviados (gerado)
â”‚   â”‚
â”‚   â””â”€â”€ prompts/
â”‚       â”œâ”€â”€ asr_prompt.txt              # Prompt de transcriÃ§Ã£o com vocabulÃ¡rio Yanomami
â”‚       â”œâ”€â”€ nlu_prompt.txt              # (Fase 3) Prompt de extraÃ§Ã£o estruturada
â”‚       â””â”€â”€ explanation_prompt.txt      # (Fase 4) Prompt de explicaÃ§Ã£o mÃ©dica
â”‚
â”œâ”€â”€ frontend/                            # (Fase 5) Interface React
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ Saude_Yanomami.pdf              # Documento base de conhecimento
â”‚
â”œâ”€â”€ .env                                 # VariÃ¡veis de ambiente (nÃ£o versionado)
â”œâ”€â”€ .env.example                         # Template de configuraÃ§Ã£o
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Roadmap de ImplementaÃ§Ã£o

### Fase 1 â€” RAG e Processamento de Base de Conhecimento

- Criar PDF com vocabulÃ¡rio indÃ­gena + sintoma biomÃ©dico
- Carregar PDF
- Criar pipeline de limpeza de texto
- Implementar chunking e embeddings (HuggingFace)
- Indexar conhecimento no FAISS
- Configurar retrieval semÃ¢ntico

### Fase 2 â€” MÃ³dulo de Entrada (Ãudio/Texto)

- Endpoint para entrada de texto: `POST /api/relatos/texto`
- Endpoint para upload de Ã¡udio: `POST /api/relatos/audio`
- TranscriÃ§Ã£o de Ã¡udio usando Gemini com prompt enriquecido (vocabulÃ¡rio Yanomami)
- Armazenamento dos relatos brutos no banco
- ValidaÃ§Ã£o mÃ­nima com pelo menos 5 dados mockados de texto e Ã¡udio

### Fase 3 â€” EstruturaÃ§Ã£o de Dados com RAG

- Criar prompt de extraÃ§Ã£o estruturada em JSON
- Integrar RAG para buscar termos indÃ­genas relacionados aos sintomas
- Extrair: sintomas (pt-br), termos nativos correspondentes, significados
- Normalizar sintomas identificados
- Endpoint: `POST /api/relatos/estruturar`
- Salvar dados estruturados no banco
- Testar com no mÃ­nimo 5 dados mockados

**Schema de saÃ­da esperado:**

```json
{
  "relato_original": "string",
  "paciente_nome": "string ou null",
  "paciente_sexo": "M | F | Indefinido",
  "sintomas_identificados_ptbr": ["sintoma1", "sintoma2"],
  "correspondencia_indigena": [
    {
      "termo_nativo": "termo yanomami",
      "significado_aproximado": "traduÃ§Ã£o",
      "contexto_cultural_saude": "explicaÃ§Ã£o"
    }
  ],
  "categoria_sintoma": "categoria",
  "idade_paciente": "string ou null",
  "duracao_sintomas": "string ou null",
  "fator_desencadeante": "string ou null",
  "temperatura_graus": "float ou null",
  "pressao_arterial": "string ou null"
}
```

### Fase 4 â€” GeraÃ§Ã£o de ExplicaÃ§Ãµes MÃ©dicas

- Criar prompt para explicaÃ§Ã£o mÃ©dica baseada nos sintomas estruturados
- Usar Gemini para gerar explicaÃ§Ã£o contextualizada
- Incluir gravidade e recomendaÃ§Ãµes bÃ¡sicas
- Endpoint: `POST /api/relatos/explicar`
- Salvar explicaÃ§Ã£o vinculada ao caso

### Fase 5 â€” Interface e Dashboard

- Tela de entrada: formulÃ¡rio de texto + upload de Ã¡udio (pode enviar um arquivo de Ã¡udio ou gravar na hora)
- Tela de visualizaÃ§Ã£o do caso individual:
  - Relato original
  - Dados estruturados
    - Sintomas mÃ©dicos
    - Termos indÃ­genas e explicaÃ§Ã£o do que eles significam naquele contexto
    - Data/hora do caso
  - ExplicaÃ§Ã£o mÃ©dica
- Dashboard bÃ¡sico:
  - Total de casos registrados
  - Sintomas mais frequentes
  - Lista de casos recentes com filtros (data, sintoma)

### Fase 6 â€” Testes e ValidaÃ§Ã£o

- Testes de integraÃ§Ã£o: entrada â†’ estruturaÃ§Ã£o â†’ explicaÃ§Ã£o â†’ exibiÃ§Ã£o
- ValidaÃ§Ã£o do RAG: verificar se termos indÃ­genas corretos sÃ£o recuperados
- ValidaÃ§Ã£o do ASR: verificar se estÃ¡ reconhecendo as palavras indÃ­genas
- ValidaÃ§Ã£o da estruturaÃ§Ã£o: comparar com casos anotados manualmente
- Testes de usabilidade: registrar relato por voz e texto

## Estrutura do Banco de Dados

```sql
-- Tabela de relatos brutos
cases (
  id,
  relato_original,
  tipo_entrada (audio/texto),
  created_at
)

-- Tabela de dados estruturados
structured_data (
  id,
  case_id,
  -- Dados do paciente
  paciente_nome,
  paciente_sexo (M/F/Indefinido),
  -- Sintomas
  sintomas_ptbr,
  termos_indigenas,
  categoria_sintoma,
  -- Dados clÃ­nicos
  idade_paciente,
  duracao_sintomas,
  fator_desencadeante,
  temperatura_graus,
  pressao_arterial,
  created_at
)

-- Tabela de explicaÃ§Ãµes mÃ©dicas
medical_explanations (
  id,
  case_id,
  explicacao,
  gravidade_sugerida,
  created_at
)
```

## Como Executar

### PrÃ©-requisitos

- Python 3.8+
- Node.js 16+ (para o frontend - Fase 5)

### 1. Testar RAG (Fase 1) - Linha de comando

```bash
# Navegar para o backend
cd backend

# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar .env com GOOGLE_API_KEY
cp ../.env.example ../.env

# Adicionar arquivo Saude_Yanomami.pdf na pasta data/
# Copiar: data/Saude_Yanomami.pdf

# Executar teste do RAG
python rag/rag_pipeline.py
```

### 2. API FastAPI (Fase 2) - Endpoints de entrada de dados

```bash
# Navegar para o backend (se ainda nÃ£o estiver)
cd backend

# Instalar dependÃªncias (se ainda nÃ£o instalou)
pip install -r requirements.txt

# Configurar .env (se ainda nÃ£o configurou)
cp ../.env.example ../.env

# Executar servidor FastAPI
python main.py
# OU
uvicorn main:app --reload

# Servidor disponÃ­vel em: http://localhost:8000
# DocumentaÃ§Ã£o Swagger: http://localhost:8000/docs
```

#### Testando os endpoints no Swagger

1. Acesse `http://localhost:8000/docs`
2. Teste o endpoint `POST /api/relatos/texto`:

   - Clique em "Try it out"
   - Insira um relato de exemplo:
     ```json
     {
       "relato": "Estou com dor de cabeÃ§a forte hÃ¡ 3 dias e febre Ã  noite"
     }
     ```
   - Clique em "Execute"

3. Teste o endpoint `POST /api/relatos/audio`:

   - Clique em "Try it out"
   - FaÃ§a upload de um arquivo de Ã¡udio (mp3, wav, m4a)
   - Clique em "Execute"
   - O Ã¡udio serÃ¡ transcrito automaticamente usando Gemini

4. Liste os relatos com `GET /api/relatos`
